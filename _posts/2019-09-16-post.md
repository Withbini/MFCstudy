---
title: "Cuda video decoder 동영상 공부 정리"
date: 2019-09-16
---

네이버 d2에 좋은 자료가 있어서 정리해보았다[FFmpeg을 이용한 Android 동영상 플레이어 개발]

이 문서는 FFmpeg을 이용하여 안드로이드에서 동영상 플레이어를 만드는 과정을 설명한다.
동영상 파일이 어떤 과정을 거쳐 재생될 수 있는지 볼 수 있어서 정리해보았다.

[FFmpeg을 이용한 Android 동영상 플레이어 개발]:https://d2.naver.com/helloworld/8794


동영상 원리
====
용어정리
--
* 동영상 압축 코덱 : 최소한의 정지 영상 정보만으로 오나전한 동영상 정보를 만들어 낼 수 있도록
동영상 정보를 압축하는 알고리즘

* 동영상 파일 : Digital Container Format을 동영상/오디오 코덱을 이용하여 데이터를 
저장하는 방식과 재생 동기화 정보 등의 부가 정보가 담긴 파일형식

* 동영상 플레이어 : Digital Container Format을 읽어 동영상을 재생할 수 있는 프로그램

* 인코딩 : 원본 영상 데이터를 특정 영상 코덱을 이용하여 압축하는 것

* Muxing : 변환한 데이터를 파일에 담는 것

* Demuxing : 동영상 파일에서 비트 스트림 데이터를 추출 => 어떤 코덱으로 인코딩 
됐는지 확인 가능 
=> 적합한 코덱으로 디코딩하면 원본 데이터영상 추출 가능

Cuda video deocder 예제는 nvdecoder와 nvencoder라고 nvidia에서 만든 자체 디코더 인코더를 사용했다. 
하지만 FFmpeg이라는 오픈소스 프레임워크도 있는데, 이 역시도 인코딩/디코딩, 먹싱/디먹싱, 스트림, 재생 등의 기능이 가능하다.

FFmpeg
--
FFmpeg에서 동영상 재생 원리를 알 수 있었다.
1. > 비디오 파일에서 libavformat으로 demuxing 
=>비트스트림 데이터를 얻어 어떤 코덱을 사용했는지 파악한다.
2. >libavcodec으로 decoding
 => 추출 코덱 정보를 바탕으로 적합한 디코더를 선택하여 원본 데이터를 추출한다.
3. >libswsalce 이용하여 YUY 픽셀 데이터를 RGB픽셀로 변경
4. >OpenGL 등을 이용하여 화면에 픽셀 데이터를 뿌려준다 => 이 때 픽셀 데이터는 처리 능력 향상을 위해 원본 동영상 프레임보다 더 넓은데, 이 픽셀 데이터보다 큰 텍스쳐를 만든다.
텍스쳐에 픽셀 데이터를 복사하고 원래의 동영상 프레임 크기만큼의 텍스쳐만 화면에 표시한다.

안드로이드 오디오 재생
---
안드로이드에서는 AudioTrack클래스가 PCM 데이터를 JNI를 통해 AudioFlinger로 보내고, 이것이 오디오 디바이스로 소리를 출력할 수 있게 한다.
재밌는 점은 SDL의 경우 오디오 디바이스에 출력할 데이터가 필요할 경우 콜백함수를 호출하여
필요한만큼 데이터를 디코딩한다는 것이다.

NVDecoder에서는 디코딩하면서 디코딩된 프레임을 큐에 넣어두는데 이때 디코딩하는 함수가 콜백으로 호출된다.
NVDecoder도 마찬가지로 디바이스에 출력할 데이터가 필요할 경우 디코딩함수가 호출되는 것이라면, 이부분이 사실 
성능을 떨어뜨리는 원인이 될 수 있다는 생각도 든다. 물론 데이터가 필요한 경우가 어떤 경우인지 알아야하겠지만 말이다.
