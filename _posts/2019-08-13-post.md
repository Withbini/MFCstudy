---
title: "video decoder & CNN 이해하기"
date: 2019-08-13
---
video decoder
=====================
### 32->64비트 전환
visual studio에서 32비트 프로그램을 64비트로 전환하기 위해서는 디버거 옵션을 x64로 변환시켜야할 뿐만 아니라,
라이브러리도 64비트용으로 해야한다. 이 부분에서 많은 시간을 투자한 것 같다.


### 이미지 버튼
owner draw를 사용하여 이미지 버튼을 꾸밀 수 있는 것을 알 수 있었다. 핸들을 이용하는데, 좀 더 알아볼 필요가 있다.

### FPS가 나오지 않는 문제에 대해
아래는 교수님과 상의한 내용이다.
fps가 나오지 않는 원인을 2가지라고 생각할 수 있다.
첫째는 꺼진 채널에서도 스레드가 돌면서 CPU를 잡아먹는 것이고, 둘째는 실제 initCudaVideo() 함수에서 디코딩하고 파싱하는데 오래걸려서
문제가 생기는 경우이다.
채널이 꺼졌음에도 불구하고, 스레드는 계속 살아 있고 for문을 계속 돈다.
물론 채널이 꺼져있을 때에는 sleep함수로 CPU를 잡아먹지 않으나, sleep 시간이 0.1초로 매우 짧아 이 효과를 보기 힘들다.
sleep 시간을 늘려 채널이 꺼져있을 때에는 스레드가 죽어있는 것을 확실하게 알아볼 필요가 있다고 했다.

두번째는 initCudaVideo()에서 디코딩과 파싱이 오래 걸리는 경우이다. 디코딩과 파싱이 오래 걸려서 framequeue를 제때 채우지 못한다면,
렌더링 자체가 느려질 수밖에 없기에 디코딩과 파싱에 시간이 얼마나 걸리는지 확인해봐야 할 것이다.

그런데 지금 쓰면서 생각난건데, 만약에 렌더링 자체에 오랜 시간이 걸리는 경우에는 어떨까?
디코딩과 파싱은 제때 잘 했으나 렌더링(frame을 texture로 바꾸고 direct surface에 그리는 것)에 시간이 오래 걸릴 가능성도 생각해야한다.

물론 모듈초기화하는데에 시간이 채널이 늘어날수록 오래 걸리는 것은 확인된 사실이다.
채널이 늘어감에 따라 시간이 linear하게 늘어나는지는 다시 한 번 확인해봐야 할 사항이다.(디코딩이 채널의 갯수에 따라 linear하게 증가하는지)
만약 linear하게 증가한다면, 이 증가분이 실제 채널 수 증가에 따른 시간 증가량에 일치하는지도 확인해봐야한다.
즉, 채널 갯수를 늘렸더니 각 프레임 별 디코딩 및 파싱하는 시간이 늘어났고 그 시간을 모두 합한 값이, 채널 증가에 따른 overhead라고 말할 수 
있는지 확인해봐야할 필요가 있다.

CNN
=================
Deepstream의 코드를 이해하기 위해 .caffemodel 파일 및 .prototxt 파일을 먼저 이해하려고 했다.
참고한 링크는 다음과 같다[^1]

먼저 CNN은 학습과 추론이라는 두가지 과정이 있다.
특정 개체로 라벨링된 데이터를 가지고 모델을 학습시켜, 학습된 모델을 이용하여 분류되어있지 않은 데이터셋에서 특정개체를 식별한다.

Caffe는 버클리 비젼, 학습 센터(Berkeley Vision and Learning Center:BVLC)에서 만든 딥러닝 프레임워크이다.
C++로 작성되었으며 python과 Matlab 바인딩을 포함하고 있다고 한다.

Caffe로 CNN을 훈련하기 위해서는 4가지 과정을 거쳐 훈련한다.
데이터 준비 - 모델 정의 - Solver 정의 - 훈련
'데이터 준비'에서는 caffe에서 이미지를 읽기 위해 DB처럼 LMDB로 만든다.
'모델 정의' 및 'Solver 정의'에서는 CNN 모델에 대한 정의, 그리고 모델 최적화를 위한 파라미터를 .prototxt에 적는다(?)
'훈련'에서는 Caffe 명령어를 통해 모델을 훈련시키고 output으로 .caffemodel 파일로 훈련된 모델이 나온다.

흥미로운 점은
데이터 준비 과정에서 사진을 모두 특정 크기로 맞추고 채도를 맞춘다(histogram equalization)는 점이다.
특정 크기로 맞추고 채도를 맞춰 서로 다른 사진간에서 픽셀간 차이가 얼마나 나는지 확인하는 방식인 것 같다.
인간의 인식과정이 어떠한지는 모르지만 과연 컴퓨터스럽다싶다.

Deepstream 시작 전에
====================
Deepstream 이해에 앞서 간략하게 딥러닝 모델의 구조에 대해 설명 들은 바를 정리하고자 한다.
먼저 위의 CNN 모델처럼 학습된 모델을 가지고 추론을 한다. 이 모델이 하는 역할을 object detection이라고 하자.
특정 이미지에 대해 "이 이미지가 될 수 있는 TOP5는 다음 5개가 있고 각각 이미지에 해당할 확률이 이만큼이다"
라는 vector가 있고 이 vector 값을 output으로 반환한다.
object detection 이후 bounding box의 경우에 이 개체는 무엇이며, 어떤 위치에 있다는 정보를 담고 있는 vector를 output으로 내놓는다.
segmentation이 될 수도 있는데, 이 경우는 살짝 복잡하지만 위와 같이 좌표값을 포함한 정보를 반환할 것이다.

즉, 내가 원하는 엔진을 쓰려고 해도 인풋과 아웃풋이 같지 않으면 그 모델은 쓸 수 없다는 것이 핵심이었다.
gdb를 통해서 코드 분석이 더 필요할 것 같다.

#### Reference
[^1]:https://kyubot.tistory.com/97
